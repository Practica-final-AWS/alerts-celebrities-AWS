AWSTemplateFormatVersion: '2010-09-09'
Description: S3 to SQS to Lambda with Rekognition and DynamoDB.
# The test actually worked!!!
Resources:
  # 0. This bucket is not part of the architecture: just a test to verify if CF actually receives new changes
  MyBucket:
    Type: AWS::S3::Bucket
    Properties:
      Tags:
        - Key: PipelineTest
          Value: UpdateSuccessful
# 0.1 This bucket is not part of the architecture: just a test to verify if CF actually receives new changes
  # First Bucket
  PrimaryCelebrityBucket: # Unique Logical ID 1
    Type: AWS::S3::Bucket
    Properties:
      Tags:
        - Key: PipelineTest
          Value: FirstBucketSuccess
  # Second Bucket
  BackupCelebrityBucket: # Unique Logical ID 2
    Type: AWS::S3::Bucket
    Properties:
      Tags:
        - Key: PipelineTest
          Value: SecondBucketSuccess
  # 1. DynamoDB Table
  CelebrityResultsTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: CelebrityDetectionResults
      AttributeDefinitions:
        - AttributeName: ImageKey
          AttributeType: S
      KeySchema:
        - AttributeName: ImageKey
          KeyType: HASH
      BillingMode: PAY_PER_REQUEST

  # 2. SQS Queue
  ImageProcessQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: image-processing-queue

  # 3. SQS Policy (Allows S3 to send messages)
  QueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues:
        - !Ref ImageProcessQueue
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Action: sqs:SendMessage
            Resource: !GetAtt ImageProcessQueue.Arn
            Condition:
              ArnLike:
                # We hardcode the ARN structure to break the dependency loop
                aws:SourceArn: !Sub "arn:aws:s3:::celebrity-upload-bucket-${AWS::AccountId}"
  # 4. S3 Bucket
  ImageBucket:
    Type: AWS::S3::Bucket
    DependsOn: QueuePolicy
    Properties:
      BucketName: !Sub "celebrity-upload-bucket-${AWS::AccountId}"
      NotificationConfiguration:
        QueueConfigurations:
          - Event: s3:ObjectCreated:*
            Queue: !GetAtt ImageProcessQueue.Arn

  # 5. Lambda Execution Role
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaPermissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - s3:GetObject
                  - rekognition:RecognizeCelebrities
                  - dynamodb:PutItem
                  - sqs:ReceiveMessage
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                Resource: "*"

  # 6. Lambda Function
  CelebrityLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: CelebrityRecognitionHandler
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.11
      Environment:
        Variables:
          TABLE_NAME: !Ref CelebrityResultsTable
      Code:
        ZipFile: |
          import boto3
          import os
          import json

          rekognition = boto3.client('rekognition')
          dynamodb = boto3.resource('dynamodb')
          table = dynamodb.Table(os.environ['TABLE_NAME'])

          def handler(event, context):
              for record in event['Records']:
                  # SQS body contains the S3 event
                  s3_event = json.loads(record['body'])
                  if 'Records' not in s3_event: continue
                  
                  for s3_rec in s3_event['Records']:
                      bucket = s3_rec['s3']['bucket']['name']
                      key = s3_rec['s3']['object']['key']
                      
                      # Call Rekognition
                      response = rekognition.recognize_celebrities(
                          Image={'S3Object': {'Bucket': bucket, 'Name': key}}
                      )
                      
                      celebs = response.get('CelebrityFaces', [])
                      is_celebrity = len(celebs) > 0
                      celeb_name = str(celebs[0]['Name']) if is_celebrity else "None"
                      
                      # Save to DynamoDB
                      table.put_item(Item={
                          'ImageKey': key,
                          'IsCelebrity': is_celebrity,
                          'CelebrityName': celeb_name,
                          'Bucket': bucket
                      })
              return {"status": "success"}

  # 7. SQS-to-Lambda Trigger
  LambdaEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      EventSourceArn: !GetAtt ImageProcessQueue.Arn
      FunctionName: !Ref CelebrityLambda
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: codepipeline.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: PipelineExtendedAccess
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:*
                  - cloudformation:*
                  - iam:PassRole
                  - codeconnections:UseConnection # THIS IS THE MISSING KEY
                  - codestar-connections:UseConnection
                Resource: "*"

  # THE ACTUAL PIPELINE
  CelebrityDetectorPipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      RoleArn: !GetAtt AppPipelineRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref WebsiteBucket # Or a separate artifact bucket if you prefer
      Stages:
        - Name: Source
          Actions:
            - Name: GitHub_Source
              ActionTypeId:
                Category: Source
                Owner: AWS
                Provider: CodeStarSourceConnection
                Version: "1"
              Configuration:
                ConnectionArn: "arn:aws:codeconnections:us-east-1:498747779442:connection/282f8ea4-1b52-4a4c-9471-1bf28f8a9912"
                FullRepositoryId: "Practica-final-AWS/alerts-celebrities-AWS"
                BranchName: "main"
              OutputArtifacts:
                - Name: SourceArtifact
        - Name: Deploy
          Actions:
            - Name: S3_Deploy
              ActionTypeId:
                Category: Deploy
                Owner: AWS
                Provider: S3
                Version: "1"
              Configuration:
                BucketName: !Ref WebsiteBucket
                Extract: "true"
              InputArtifacts:
                - Name: SourceArtifact

Outputs:
  MyIdentityPoolId:
    Description: "Copy this into your index.html"
    Value: !Ref IdentityPool
  WebsiteURL:
    Description: "Your Live Website Link"
    Value: !GetAtt WebsiteBucket.WebsiteURL
>>>>>>> fa6708407dfde98058520cd2680291b5bc119199
